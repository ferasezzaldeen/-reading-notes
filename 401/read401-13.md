# ***Linear Regressions***
## Scikit-learn:
 is a powerful Python module for machine learning. It contains function for regression, classification, clustering, model selection and dimensionality reduction. Today, I will explore the sklearn.linear_model module which contains “methods intended for regression in which the target value is expected to be a linear combination of the input variables”.



## Exploring Boston Housing Data Set

The first step is to import the required Python libraries into Ipython Notebook.

![dvdv](https://bigdata-madesimple.com/wp-content/uploads/2016/04/Explore-1.png)

This data set is available in sklearn Python module, so I will access it using scikitlearn. I am going to import Boston data set into Ipython notebook and store it in a variable called boston.

![dvdv](https://bigdata-madesimple.com/wp-content/uploads/2016/04/sklearn.png)


The object boston is a dictionary, so you can explore the keys of this dictionary.

![dvdv](https://bigdata-madesimple.com/wp-content/uploads/2016/04/boston-keys.png)

## Scikit Learn
In this section I am going to fit a linear regression model and predict the Boston housing prices. I will use the least squares method as the way to estimate the coefficients.

Y = boston housing price(also called “target” data in Python)

and

X = all the other features (or independent variables)

First, I am going to import linear regression from sci-kit learn module. Then I am going to drop the price column as I want only the parameters as my X values. I am going to store linear regression object in a variable called lm.

![vfvf](https://bigdata-madesimple.com/wp-content/uploads/2016/04/Skitlearn-linear-model1.png)

If you want to look inside the linear regression object, you can do so by typing LinearRegression. and the press <tab> key. This will give a list of functions available inside linear regression object.

![fvfv](https://bigdata-madesimple.com/wp-content/uploads/2016/04/linear-regression.png)

Important functions to keep in mind while fitting a linear regression model are:

lm.fit() -> fits a linear model

lm.predict() -> Predict Y using the linear model with estimated coefficients

lm.score() -> Returns the coefficient of determination (R^2). A measure of how well observed outcomes are replicated by the model, as the proportion of total variation of outcomes explained by the model.



## Fitting a Linear Model
I am going to use all 13 parameters to fit a linear regression model. Two other parameters that you can pass to linear regression object are fit_intercept and normalize.

In [20]: lm.fit(X, bos.PRICE)

Out[20]: LinearRegression(copy_X=True, fit_intercept=True, normalize=False)

I am going to print the intercept and number of coefficients.

![cdc](https://bigdata-madesimple.com/wp-content/uploads/2016/04/Estimated-Coeff.png)

I then construct a data frame that contains features and estimated coefficients.

![fvfv](https://bigdata-madesimple.com/wp-content/uploads/2016/04/pd-data-frame.png)

As you can see from the data frame that there is a high correlation between RM and prices. Lets plot a scatter plot between True housing prices and True RM.

![vfvf](https://bigdata-madesimple.com/wp-content/uploads/2016/04/Relationship-between-RM-and-Price.png)

Relationship between RM and Price

As you can see that there is a positive correlation between RM and housing prices.